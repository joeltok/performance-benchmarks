{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Benchmarking: Pandas DataFrame vs List of Dictionaries\n",
    "\n",
    "Benchmark performance of pandas.DataFrame against a native python list for element-wise assignment.\n",
    "\n",
    "## Problem\n",
    "\n",
    "While in the initial stages of a project, sometimes we have to choose between storing data with pandas dataframes or in native python lists of dictionaries. Both data structures look similar enough to perform the same tasks - we can even look at lists of dictionaries as simply a less complex pandas dataframe (each row in a dataframe corresponds to each dictionary in the list). \n",
    "\n",
    "The question then arises: given the increased complexity and overhead of a pandas dataframe, is it true then that we should always default to using python lists of dictionaries when performance is the primary consideration? \n",
    "\n",
    "The answer, it would seem, is no. This we demonstrate by examining the use case of element-wise assignment**.\n",
    "\n",
    "## Setup\n",
    "\n",
    "For the dataset, we use the new_york_hotels.csv dataset. We will do the comparison using 2 different functions: a simple summation, and a haversine function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from timeit import Timer\n",
    "\n",
    "df = pd.read_csv('new_york_hotels.csv', encoding='cp1252')  # dataframe\n",
    "l  = df.to_dict('records')                                  # list of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "### 1. Summation\n",
    "\n",
    "#### Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019s for best run.\n"
     ]
    }
   ],
   "source": [
    "def timing_loop():\n",
    "    df['x'] = df['latitude'].values + df['longitude'].values\n",
    "\n",
    "df_sum_time = min(Timer(timing_loop).repeat(10, 100))\n",
    "print(f'{df_sum_time:.3f}s for best run.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021s for best run.\n"
     ]
    }
   ],
   "source": [
    "def timing_loop():\n",
    "    for o in l:\n",
    "        o['distance'] = o['latitude'] + o['longitude']\n",
    "\n",
    "list_sum_time = min(Timer(timing_loop).repeat(10, 100))\n",
    "print(f'{list_sum_time:.3f}s for best run.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Haversine\n",
    "\n",
    "#### Pandas DataFrame\n",
    "\n",
    "The haversine function we will use is the one used by [Sofia Heisler in Pycon2017](https://github.com/s-heisler/pycon2017-optimizing-pandas/blob/master/pyCon%20materials/PyCon%20un-sad%20Pandas.ipynb). This function makes use of vectorization, and is the best performing of 5 different other approaches in the same presentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027s for best run.\n"
     ]
    }
   ],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "  miles_constant = 3959\n",
    "  lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2])\n",
    "  dlat = lat2 - lat1\n",
    "  dlon = lon2 - lon1\n",
    "  a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "  c = 2 * np.arcsin(np.sqrt(a))\n",
    "  mi = miles_constant * c\n",
    "  return mi\n",
    "\n",
    "def timing_loop():\n",
    "    df['distance'] = haversine(40.671, -73.985, df['latitude'].values, df['longitude'].values)\n",
    "\n",
    "df_haversine_time = min(Timer(timing_loop).repeat(10, 100))\n",
    "print(f'{df_haversine_time:.3f}s for best run.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python List\n",
    "\n",
    "An alternative implementation of the haversine function has been optimised for use with lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.330s for best run.\n"
     ]
    }
   ],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "  miles_constant = 3959\n",
    "  lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "  dlat = lat2 - lat1\n",
    "  dlon = lon2 - lon1\n",
    "  a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "  c = 2 * math.asin(math.sqrt(a))\n",
    "  mi = miles_constant * c\n",
    "  return mi\n",
    "\n",
    "def timing_loop():\n",
    "    for o in l:\n",
    "        lat = o['latitude']\n",
    "        lon = o['longitude']\n",
    "        o['distance'] = haversine(40.671, -73.985, lat, lon)\n",
    "\n",
    "list_haversine_time = min(Timer(timing_loop).repeat(10, 100))\n",
    "print(f'{list_haversine_time:.3f}s for best run.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "From the above, we can see that for summation, the dataframe implementation is only slightly faster than the list implementation. This difference is much more pronounced for the more complicated haversine function, where the dataframe implementation is about 10X faster than the list implementation. \n",
    "\n",
    "This is surprising. Some further digging establishes the reasons for this - pandas implements additional optimisations in many use cases, some of these in C code. Such optimisations like [vectorization](https://datascience.blog.wzb.eu/2018/02/02/vectorization-and-parallelization-in-python-with-numpy-and-pandas/) add a level of power to pandas dataframes that would be hard and/or time-consuming to emulate while using native data structures, like a list of dictionaries in this case. \n",
    "\n",
    "## References\n",
    "\n",
    "- https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6\n",
    "- https://github.com/s-heisler/pycon2017-optimizing-pandas\n",
    "- https://leadsift.com/loop-map-list-comprehension/\n",
    "- http://effbot.org/zone/python-list.htm\n",
    "\n",
    "** Element-wise assignment in this case refers to the iterating of a list of dictionaries, running computations on the values of each individual dictionary, and then assigning the result of that computation onto the same dictionary. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
